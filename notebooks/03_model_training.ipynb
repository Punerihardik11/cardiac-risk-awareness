{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e88f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (5160, 44)\n",
      "Target shape: (5160,)\n",
      "Target distribution:\n",
      "target\n",
      "0.0    4007\n",
      "1.0    1153\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>age</th>\n",
       "      <th>ca</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>cp</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_missing</th>\n",
       "      <th>heartRate_missing</th>\n",
       "      <th>oldpeak_missing</th>\n",
       "      <th>prevalentHyp_missing</th>\n",
       "      <th>prevalentStroke_missing</th>\n",
       "      <th>restecg_missing</th>\n",
       "      <th>slope_missing</th>\n",
       "      <th>sysBP_missing</th>\n",
       "      <th>thal_missing</th>\n",
       "      <th>totChol_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.088785</td>\n",
       "      <td>0</td>\n",
       "      <td>1.435909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.088785</td>\n",
       "      <td>0</td>\n",
       "      <td>1.887489</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.088785</td>\n",
       "      <td>0</td>\n",
       "      <td>1.887489</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088785</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.499358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.088785</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.047778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BMI  BPMeds       age   ca  cigsPerDay               cp  \\\n",
       "0 -0.088785       0  1.435909  0.0         0.0   typical angina   \n",
       "1 -0.088785       0  1.887489  3.0         0.0     asymptomatic   \n",
       "2 -0.088785       0  1.887489  2.0         0.0     asymptomatic   \n",
       "3 -0.088785       0 -1.499358  0.0         0.0      non-anginal   \n",
       "4 -0.088785       0 -1.047778  0.0         0.0  atypical angina   \n",
       "\n",
       "   currentSmoker  diaBP  diabetes  education  ...  glucose_missing  \\\n",
       "0              0   82.0         0        2.0  ...                1   \n",
       "1              0   82.0         0        2.0  ...                1   \n",
       "2              0   82.0         0        2.0  ...                1   \n",
       "3              0   82.0         0        2.0  ...                1   \n",
       "4              0   82.0         0        2.0  ...                1   \n",
       "\n",
       "   heartRate_missing  oldpeak_missing  prevalentHyp_missing  \\\n",
       "0                  0                0                     1   \n",
       "1                  0                0                     1   \n",
       "2                  0                0                     1   \n",
       "3                  0                0                     1   \n",
       "4                  0                0                     1   \n",
       "\n",
       "   prevalentStroke_missing  restecg_missing  slope_missing sysBP_missing  \\\n",
       "0                        1                0              0             0   \n",
       "1                        1                0              0             0   \n",
       "2                        1                0              0             0   \n",
       "3                        1                0              0             0   \n",
       "4                        1                0              0             0   \n",
       "\n",
       "  thal_missing totChol_missing  \n",
       "0            0               0  \n",
       "1            0               0  \n",
       "2            0               0  \n",
       "3            0               0  \n",
       "4            0               0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Imports & Load Model-Ready Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load preprocessed features and target\n",
    "X = pd.read_csv(\"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\X_scaled.csv\")\n",
    "y = pd.read_csv(\"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\y.csv\").squeeze()\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Target distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb3f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Encode Categorical Features\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CATEGORICAL ENCODING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Categorical columns found: {categorical_cols}\")\n",
    "\n",
    "if categorical_cols:\n",
    "    # Label encode each categorical feature\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "        print(f\"âœ“ Encoded {col}\")\n",
    "    print(f\"\\nâœ“ All categorical features encoded\")\n",
    "else:\n",
    "    print(\"âœ“ No categorical features found\")\n",
    "    label_encoders = {}\n",
    "\n",
    "print(f\"Final shape: {X.shape}\")\n",
    "print(f\"Data types:\\n{X.dtypes.value_counts()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc666709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAIN/TEST SPLIT\n",
      "======================================================================\n",
      "X_train shape: (4128, 44)\n",
      "X_test shape: (1032, 44)\n",
      "y_train shape: (4128,)\n",
      "y_test shape: (1032,)\n",
      "\n",
      "Target distribution (train): {0.0: 3206, 1.0: 922}\n",
      "Target distribution (test): {0.0: 801, 1.0: 231}\n",
      "\n",
      "âœ“ Stratified split validated\n",
      "Categorical columns to encode: []\n",
      "\n",
      "All features now numeric. Shape: (5160, 44)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Split Features & Target (Train/Test)\n",
    "\n",
    "# Stratified split (preserves target distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nTarget distribution (train): {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Target distribution (test): {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0], \"Train size mismatch!\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"Test size mismatch!\"\n",
    "\n",
    "print(\"\\nâœ“ Stratified split validated\")\n",
    "\n",
    "# Cell 2: Encode Categorical Features\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns to encode: {categorical_cols}\")\n",
    "\n",
    "# Label encode each categorical feature\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"âœ“ Encoded {col}: {le.classes_.tolist()}\")\n",
    "\n",
    "print(f\"\\nAll features now numeric. Shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e812aeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAIN/VALIDATION SPLIT (STRATIFIED)\n",
      "======================================================================\n",
      "X_train shape: (4128, 44)\n",
      "X_val shape: (1032, 44)\n",
      "y_train shape: (4128,)\n",
      "y_val shape: (1032,)\n",
      "\n",
      "Class distribution (train): {0.0: 3206, 1.0: 922}\n",
      "Class distribution (val): {0.0: 801, 1.0: 231}\n",
      "\n",
      "âœ“ Stratification ensures balanced medical dataset splits\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Trainâ€“Validation Split (Stratified)\n",
    "\n",
    "# Stratified split (critical for medical datasets to preserve class balance)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAIN/VALIDATION SPLIT (STRATIFIED)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "\n",
    "print(f\"\\nClass distribution (train): {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Class distribution (val): {y_val.value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\nâœ“ Stratification ensures balanced medical dataset splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74cc913a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "âœ“ Model trained on 4128 samples\n",
      "âœ“ Features: 44\n",
      "âœ“ Class weights: balanced (handles imbalance)\n",
      "âœ“ Solver: liblinear (medical-grade stability)\n",
      "\n",
      "Model coefficients shape: (1, 44)\n",
      "Intercept: -1.4414\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train Baseline Logistic Regression\n",
    "\n",
    "# Logistic Regression with balanced class weights (critical for medical data)\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BASELINE LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ“ Model trained on {X_train.shape[0]} samples\")\n",
    "print(f\"âœ“ Features: {X_train.shape[1]}\")\n",
    "print(f\"âœ“ Class weights: balanced (handles imbalance)\")\n",
    "print(f\"âœ“ Solver: liblinear (medical-grade stability)\")\n",
    "\n",
    "print(f\"\\nModel coefficients shape: {log_reg.coef_.shape}\")\n",
    "print(f\"Intercept: {log_reg.intercept_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0ef8108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATION PREDICTIONS\n",
      "======================================================================\n",
      "Prediction shape: (1032,)\n",
      "Probability shape: (1032,)\n",
      "Unique predictions: [0. 1.]\n",
      "Probability range: [0.0666, 0.9997]\n",
      "\n",
      "Prediction distribution:\n",
      "{0.0: 696, 1.0: 336}\n",
      "\n",
      "âœ“ Predictions & probabilities computed\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Predictions & Probabilities\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_val_pred = log_reg.predict(X_val)\n",
    "y_val_proba = log_reg.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VALIDATION PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Prediction shape: {y_val_pred.shape}\")\n",
    "print(f\"Probability shape: {y_val_proba.shape}\")\n",
    "print(f\"Unique predictions: {np.unique(y_val_pred)}\")\n",
    "print(f\"Probability range: [{y_val_proba.min():.4f}, {y_val_proba.max():.4f}]\")\n",
    "\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(pd.Series(y_val_pred).value_counts().to_dict())\n",
    "\n",
    "print(\"\\nâœ“ Predictions & probabilities computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2aae503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATION METRICS (CARDIAC RISK FOCUS)\n",
      "======================================================================\n",
      "Accuracy:  0.7548\n",
      "Precision: 0.4673\n",
      "Recall:    0.6797  â† CRITICAL (identifies high-risk patients)\n",
      "F1 Score:  0.5538\n",
      "ROC-AUC:   0.8085\n",
      "\n",
      "Confusion Matrix:\n",
      "  True Negatives:  622\n",
      "  False Positives: 179\n",
      "  False Negatives: 74  â† Critical: Missed cardiac risk\n",
      "  True Positives:  157\n",
      "\n",
      "======================================================================\n",
      "Classification Report:\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.78      0.83       801\n",
      "         1.0       0.47      0.68      0.55       231\n",
      "\n",
      "    accuracy                           0.75      1032\n",
      "   macro avg       0.68      0.73      0.69      1032\n",
      "weighted avg       0.80      0.75      0.77      1032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluation Metrics (Core Artifact)\n",
    "\n",
    "# Calculate all metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "recall = recall_score(y_val, y_val_pred, zero_division=0)\n",
    "f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VALIDATION METRICS (CARDIAC RISK FOCUS)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}  â† CRITICAL (identifies high-risk patients)\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Negatives:  {cm[0, 0]}\")\n",
    "print(f\"  False Positives: {cm[0, 1]}\")\n",
    "print(f\"  False Negatives: {cm[1, 0]}  â† Critical: Missed cardiac risk\")\n",
    "print(f\"  True Positives:  {cm[1, 1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0985e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONFUSION MATRIX ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "              Predicted\n",
      "            Negative  Positive\n",
      "Actual Neg     622       179   (True Neg / False Pos)\n",
      "Actual Pos      74       157   (False Neg / True Pos)\n",
      "\n",
      "Sensitivity (Recall): 0.6797 â†’ Detects 68.0% of cardiac risk\n",
      "Specificity: 0.7765 â†’ Correctly rules out 77.7% of healthy\n",
      "False Negative Rate: 0.3203 â†’ 74 missed cardiac cases\n",
      "\n",
      "âœ“ Confusion matrix analyzed\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Confusion Matrix Interpretation\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFUSION MATRIX ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n              Predicted\")\n",
    "print(f\"            Negative  Positive\")\n",
    "print(f\"Actual Neg    {cm[0, 0]:4d}      {cm[0, 1]:4d}   (True Neg / False Pos)\")\n",
    "print(f\"Actual Pos    {cm[1, 0]:4d}      {cm[1, 1]:4d}   (False Neg / True Pos)\")\n",
    "\n",
    "# Calculate rates\n",
    "tn, fp, fn, tp = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "false_neg_rate = fn / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f\"\\nSensitivity (Recall): {sensitivity:.4f} â†’ Detects {sensitivity*100:.1f}% of cardiac risk\")\n",
    "print(f\"Specificity: {specificity:.4f} â†’ Correctly rules out {specificity*100:.1f}% of healthy\")\n",
    "print(f\"False Negative Rate: {false_neg_rate:.4f} â†’ {int(fn)} missed cardiac cases\")\n",
    "\n",
    "print(\"\\nâœ“ Confusion matrix analyzed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af18f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DETAILED CLASSIFICATION REPORT\n",
      "======================================================================\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Risk       0.89      0.78      0.83       801\n",
      "Cardiac Risk       0.47      0.68      0.55       231\n",
      "\n",
      "    accuracy                           0.75      1032\n",
      "   macro avg       0.68      0.73      0.69      1032\n",
      "weighted avg       0.80      0.75      0.77      1032\n",
      "\n",
      "\n",
      "======================================================================\n",
      "KEY METRICS\n",
      "======================================================================\n",
      "Overall Accuracy: 0.7548\n",
      "Weighted Precision: 0.7982\n",
      "Weighted Recall: 0.7548\n",
      "Weighted F1: 0.7689\n",
      "\n",
      "âœ“ Classification report generated\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Classification Report\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['No Risk', 'Cardiac Risk']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Overall Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"Weighted Precision: {precision_score(y_val, y_val_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Weighted Recall: {recall_score(y_val, y_val_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Weighted F1: {f1_score(y_val, y_val_pred, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ Classification report generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9050770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL ARTIFACT SAVED\n",
      "======================================================================\n",
      "âœ“ Model saved to: c:\\Users\\Pc\\Desktop\\cardiac-risk-awareness\\notebooks\\data\\processed\\logistic_regression_model.pkl\n",
      "âœ“ Model type: Logistic Regression\n",
      "âœ“ Features: 44\n",
      "\n",
      "======================================================================\n",
      "COMPLETE INFERENCE PIPELINE\n",
      "======================================================================\n",
      "Required files for production:\n",
      "  1. scaler.pkl â†’ Feature scaling\n",
      "  2. logistic_regression_model.pkl â†’ Predictions\n",
      "  3. label_encoders (from notebook) â†’ Categorical encoding\n",
      "\n",
      "âœ“ Model ready for deployment\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Save Model Artifact\n",
    "\n",
    "# Save trained logistic regression model\n",
    "model_path = \"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\logistic_regression_model.pkl\"\n",
    "joblib.dump(log_reg, model_path)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL ARTIFACT SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ“ Model saved to: {model_path}\")\n",
    "print(f\"âœ“ Model type: Logistic Regression\")\n",
    "print(f\"âœ“ Features: {X_train.shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE INFERENCE PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Required files for production:\")\n",
    "print(\"  1. scaler.pkl â†’ Feature scaling\")\n",
    "print(\"  2. logistic_regression_model.pkl â†’ Predictions\")\n",
    "print(\"  3. label_encoders (from notebook) â†’ Categorical encoding\")\n",
    "\n",
    "print(\"\\nâœ“ Model ready for deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f21c0f",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Step 4 â€” Model Training & Validation\n",
    "\n",
    "### Baseline Model: Logistic Regression\n",
    "\n",
    "A logistic regression model was trained with balanced class weights to address class imbalance in cardiac risk prediction. This medical-grade baseline prioritizes recall (sensitivity) to minimize false negativesâ€”missed cardiac risk cases.\n",
    "\n",
    "### Key Training Decisions\n",
    "- **Class Weight Balancing**: Prevents bias toward majority class\n",
    "- **Stratified Split**: Preserves target distribution (80/20 train/val)\n",
    "- **Metric Priority**: Recall > Accuracy (missing cardiac risk is costly)\n",
    "- **Solver**: liblinear for stable convergence\n",
    "\n",
    "### Validation Results\n",
    "| Metric | Purpose |\n",
    "|--------|---------|\n",
    "| **Recall (Sensitivity)** | % of actual cardiac cases detected |\n",
    "| Specificity | % of healthy cases correctly identified |\n",
    "| Precision | Reliability of positive predictions |\n",
    "| F1-Score | Balance between precision & recall |\n",
    "| ROC-AUC | Overall discrimination ability |\n",
    "\n",
    "### Model Artifacts\n",
    "âœ“ Trained model saved (`logistic_regression_model.pkl`)  \n",
    "âœ“ Scaler artifact saved (from Step 3)  \n",
    "âœ“ Label encoders tracked (categorical encoding)  \n",
    "âœ“ **Complete inference pipeline ready for deployment**\n",
    "\n",
    "### Clinical Interpretation\n",
    "The model prioritizes identifying cardiac risk cases (high recall) even at the cost of some false positives, aligning with medical best practices where missing a disease is riskier than a false alarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792495c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
