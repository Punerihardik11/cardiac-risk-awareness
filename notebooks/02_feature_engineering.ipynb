{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b035666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5160, 24)\n",
      "\n",
      "First few rows:\n",
      "   BMI  BPMeds  age   ca  cigsPerDay               cp  currentSmoker  diaBP  \\\n",
      "0  NaN     NaN   63  0.0         NaN   typical angina            NaN    NaN   \n",
      "1  NaN     NaN   67  3.0         NaN     asymptomatic            NaN    NaN   \n",
      "2  NaN     NaN   67  2.0         NaN     asymptomatic            NaN    NaN   \n",
      "3  NaN     NaN   37  0.0         NaN      non-anginal            NaN    NaN   \n",
      "4  NaN     NaN   41  0.0         NaN  atypical angina            NaN    NaN   \n",
      "\n",
      "   diabetes  education  ... oldpeak prevalentHyp  prevalentStroke  \\\n",
      "0       NaN        NaN  ...     2.3          NaN              NaN   \n",
      "1       NaN        NaN  ...     1.5          NaN              NaN   \n",
      "2       NaN        NaN  ...     2.6          NaN              NaN   \n",
      "3       NaN        NaN  ...     3.5          NaN              NaN   \n",
      "4       NaN        NaN  ...     1.4          NaN              NaN   \n",
      "\n",
      "          restecg     sex        slope  sysBP target               thal  \\\n",
      "0  lv hypertrophy    Male  downsloping  145.0      0       fixed defect   \n",
      "1  lv hypertrophy    Male         flat  160.0      1             normal   \n",
      "2  lv hypertrophy    Male         flat  120.0      1  reversable defect   \n",
      "3          normal    Male  downsloping  130.0      0             normal   \n",
      "4  lv hypertrophy  Female    upsloping  130.0      0             normal   \n",
      "\n",
      "  totChol  \n",
      "0   233.0  \n",
      "1   286.0  \n",
      "2   229.0  \n",
      "3   250.0  \n",
      "4   204.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 5160 entries, 0 to 5159\n",
      "Data columns (total 24 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   BMI              4221 non-null   float64\n",
      " 1   BPMeds           4187 non-null   float64\n",
      " 2   age              5160 non-null   int64  \n",
      " 3   ca               309 non-null    float64\n",
      " 4   cigsPerDay       4211 non-null   float64\n",
      " 5   cp               920 non-null    str    \n",
      " 6   currentSmoker    4240 non-null   float64\n",
      " 7   diaBP            4240 non-null   float64\n",
      " 8   diabetes         4240 non-null   float64\n",
      " 9   education        4135 non-null   float64\n",
      " 10  exang            865 non-null    object \n",
      " 11  fbs              830 non-null    object \n",
      " 12  glucose          3852 non-null   float64\n",
      " 13  heartRate        5104 non-null   float64\n",
      " 14  oldpeak          858 non-null    float64\n",
      " 15  prevalentHyp     4240 non-null   float64\n",
      " 16  prevalentStroke  4240 non-null   float64\n",
      " 17  restecg          918 non-null    str    \n",
      " 18  sex              5160 non-null   str    \n",
      " 19  slope            611 non-null    str    \n",
      " 20  sysBP            5101 non-null   float64\n",
      " 21  target           5160 non-null   int64  \n",
      " 22  thal             434 non-null    str    \n",
      " 23  totChol          5080 non-null   float64\n",
      "dtypes: float64(15), int64(2), object(2), str(5)\n",
      "memory usage: 967.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load merged, cleaned dataset from Milestone 1\n",
    "data_path = \"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\heart_data_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa792482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>4851</td>\n",
       "      <td>94.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>4726</td>\n",
       "      <td>91.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>4549</td>\n",
       "      <td>88.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>4330</td>\n",
       "      <td>83.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>4302</td>\n",
       "      <td>83.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>4295</td>\n",
       "      <td>83.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>4242</td>\n",
       "      <td>82.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>4240</td>\n",
       "      <td>82.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>1308</td>\n",
       "      <td>25.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>1025</td>\n",
       "      <td>19.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMeds</th>\n",
       "      <td>973</td>\n",
       "      <td>18.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigsPerDay</th>\n",
       "      <td>949</td>\n",
       "      <td>18.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>939</td>\n",
       "      <td>18.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>920</td>\n",
       "      <td>17.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentSmoker</th>\n",
       "      <td>920</td>\n",
       "      <td>17.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaBP</th>\n",
       "      <td>920</td>\n",
       "      <td>17.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentStroke</th>\n",
       "      <td>920</td>\n",
       "      <td>17.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentHyp</th>\n",
       "      <td>920</td>\n",
       "      <td>17.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totChol</th>\n",
       "      <td>80</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysBP</th>\n",
       "      <td>59</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartRate</th>\n",
       "      <td>56</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 missing_count  missing_percent\n",
       "ca                        4851            94.01\n",
       "thal                      4726            91.59\n",
       "slope                     4549            88.16\n",
       "fbs                       4330            83.91\n",
       "oldpeak                   4302            83.37\n",
       "exang                     4295            83.24\n",
       "restecg                   4242            82.21\n",
       "cp                        4240            82.17\n",
       "glucose                   1308            25.35\n",
       "education                 1025            19.86\n",
       "BPMeds                     973            18.86\n",
       "cigsPerDay                 949            18.39\n",
       "BMI                        939            18.20\n",
       "diabetes                   920            17.83\n",
       "currentSmoker              920            17.83\n",
       "diaBP                      920            17.83\n",
       "prevalentStroke            920            17.83\n",
       "prevalentHyp               920            17.83\n",
       "totChol                     80             1.55\n",
       "sysBP                       59             1.14\n",
       "heartRate                   56             1.09\n",
       "age                          0             0.00\n",
       "sex                          0             0.00\n",
       "target                       0             0.00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = pd.DataFrame({\n",
    "    \"missing_count\": df.isna().sum(),\n",
    "    \"missing_percent\": (df.isna().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "# Sort by missing percentage (descending)\n",
    "missing_df = missing_df.sort_values(by=\"missing_percent\", ascending=False)\n",
    "\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b184a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features by Missingness Category:\n",
      "  missingness_category  count\n",
      "0          High (>50%)      8\n",
      "1          Low (1-10%)      3\n",
      "2      Medium (10-50%)     10\n",
      "3           No Missing      3\n",
      "\n",
      "======================================================================\n",
      "\n",
      "No Missing: ['age', 'sex', 'target']\n",
      "\n",
      "Low (1-10%): ['totChol', 'sysBP', 'heartRate']\n",
      "\n",
      "Medium (10-50%): ['glucose', 'education', 'BPMeds', 'cigsPerDay', 'BMI', 'diabetes', 'currentSmoker', 'diaBP', 'prevalentStroke', 'prevalentHyp']\n",
      "\n",
      "High (>50%): ['ca', 'thal', 'slope', 'fbs', 'oldpeak', 'exang', 'restecg', 'cp']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Categorize Features by Missingness Level\n",
    "\n",
    "def categorize_missingness(percent):\n",
    "    if percent == 0:\n",
    "        return \"No Missing\"\n",
    "    elif percent <= 10:\n",
    "        return \"Low (1-10%)\"\n",
    "    elif percent <= 50:\n",
    "        return \"Medium (10-50%)\"\n",
    "    else:\n",
    "        return \"High (>50%)\"\n",
    "\n",
    "missing_df[\"missingness_category\"] = missing_df[\"missing_percent\"].apply(categorize_missingness)\n",
    "\n",
    "# Group by category\n",
    "category_summary = missing_df.groupby(\"missingness_category\").size().reset_index(name=\"count\")\n",
    "print(\"Features by Missingness Category:\")\n",
    "print(category_summary)\n",
    "\n",
    "# Show features in each category\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "for category in [\"No Missing\", \"Low (1-10%)\", \"Medium (10-50%)\", \"High (>50%)\"]:\n",
    "    features = missing_df[missing_df[\"missingness_category\"] == category].index.tolist()\n",
    "    if features:\n",
    "        print(f\"\\n{category}: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f37e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features: 24 | Categorized: 24 | ‚úì Pass\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Features: {len(missing_df)} | Categorized: {category_summary['count'].sum()} | {'‚úì Pass' if len(missing_df) == category_summary['count'].sum() else '‚úó Fail'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d9e36",
   "metadata": {},
   "source": [
    "## üìä Missing Value Analysis Summary\n",
    "\n",
    "### Overview\n",
    "- **Dataset Shape**: Rows: 5160, Columns: 24\n",
    "- **Total Missing Values**: 45,524\n",
    "- **Features with Missing Data**: 21 out of 24\n",
    "\n",
    "### Missingness Categories\n",
    "The features have been categorized based on their missing value percentages:\n",
    "\n",
    "1. **No Missing** (0%) - 3 features\n",
    "   - Features with complete data\n",
    "   - Action: Can use directly without imputation\n",
    "\n",
    "2. **Low Missingness** (1-10%) - 3 features\n",
    "   - Features with minimal missing values\n",
    "   - Action: Safe to impute using simple methods (mean, median, mode)\n",
    "\n",
    "3. **Medium Missingness** (10-50%) - 10 features\n",
    "   - Features with moderate missing values\n",
    "   - Action: Use advanced imputation (KNN, iterative imputation) or consider dropping\n",
    "\n",
    "4. **High Missingness** (>50%) - 8 features\n",
    "   - Features with majority of values missing\n",
    "   - Action: Consider dropping or investigate why data is missing\n",
    "\n",
    "### Next Steps\n",
    "- Decide imputation strategy for each category\n",
    "- Handle missing values based on feature type (numeric vs categorical)\n",
    "- Validate imputed data quality\n",
    "- Prepare features for model training\n",
    "\n",
    "### Key Insights\n",
    "- 8 columns have more than 50% missing data and may have limited predictive value\n",
    "- 3 features are already complete and ready to use\n",
    "- 13 features (Low + Medium) can be imputed with appropriate strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üìå Formatting & Documentation Method\n",
    "\n",
    "### Cell Types in Jupyter Notebooks\n",
    "\n",
    "This notebook uses two primary cell types:\n",
    "\n",
    "1. **Code Cells** (`language=\"python\"`)\n",
    "   - Contains executable Python code\n",
    "   - Produces outputs (tables, visualizations, prints)\n",
    "   - Format: Wrapped in `<VSCode.Cell language=\"python\">`\n",
    "\n",
    "2. **Markdown Cells** (`language=\"markdown\"`)\n",
    "   - Contains formatted documentation\n",
    "   - No execution, purely informational\n",
    "   - Supports: Headers, bullet points, bold, links, code blocks\n",
    "   - Format: Wrapped in `<VSCode.Cell language=\"markdown\">`\n",
    "\n",
    "### Why Proper Formatting Matters\n",
    "\n",
    "- **Readability** - Markdown cells make analysis easy to follow\n",
    "- **Documentation** - Code is preserved with its explanation\n",
    "- **No Syntax Errors** - Each cell type handles its own syntax\n",
    "- **Professional Output** - Combines code + insights seamlessly\n",
    "\n",
    "### Structure of This Notebook\n",
    "\n",
    "```\n",
    "Cell 1: Load Data (Code)\n",
    "  ‚Üì\n",
    "Cell 2: Missing Value Analysis (Code)\n",
    "  ‚Üì\n",
    "Cell 3: Categorize Missingness (Code)\n",
    "  ‚Üì\n",
    "Cell 4: Sanity Check (Code)\n",
    "  ‚Üì\n",
    "Cell 5: Documentation Summary (Markdown) ‚Üê This explains findings\n",
    "  ‚Üì\n",
    "Cell 6: Method Explanation (Markdown) ‚Üê This explains how we did it\n",
    "```\n",
    "\n",
    "This layered approach keeps code executable and documentation readable! ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd5f7b",
   "metadata": {},
   "source": [
    "**Note:** Missingness thresholds were aligned to standard applied ML conventions (<5%, 5‚Äì30%, >30%) for downstream imputation decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1985e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (5160, 24)\n",
      "Missing values preserved: 45524\n",
      "‚úì Ready for imputation\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Reload Data (Safety Check)\n",
    "\n",
    "# Reload fresh copy\n",
    "df_original = df.copy()\n",
    "df_imputed = df.copy()\n",
    "\n",
    "print(f\"Original shape: {df_original.shape}\")\n",
    "print(f\"Missing values preserved: {df_original.isna().sum().sum()}\")\n",
    "print(\"‚úì Ready for imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd5291ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE TYPE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä NUMERIC FEATURES (17):\n",
      "  ‚Ä¢ BMI (float64) - Missing: 939\n",
      "  ‚Ä¢ BPMeds (float64) - Missing: 973\n",
      "  ‚Ä¢ age (int64) - Missing: 0\n",
      "  ‚Ä¢ ca (float64) - Missing: 4851\n",
      "  ‚Ä¢ cigsPerDay (float64) - Missing: 949\n",
      "  ‚Ä¢ currentSmoker (float64) - Missing: 920\n",
      "  ‚Ä¢ diaBP (float64) - Missing: 920\n",
      "  ‚Ä¢ diabetes (float64) - Missing: 920\n",
      "  ‚Ä¢ education (float64) - Missing: 1025\n",
      "  ‚Ä¢ glucose (float64) - Missing: 1308\n",
      "  ‚Ä¢ heartRate (float64) - Missing: 56\n",
      "  ‚Ä¢ oldpeak (float64) - Missing: 4302\n",
      "  ‚Ä¢ prevalentHyp (float64) - Missing: 920\n",
      "  ‚Ä¢ prevalentStroke (float64) - Missing: 920\n",
      "  ‚Ä¢ sysBP (float64) - Missing: 59\n",
      "  ‚Ä¢ target (int64) - Missing: 0\n",
      "  ‚Ä¢ totChol (float64) - Missing: 80\n",
      "\n",
      "üìù CATEGORICAL FEATURES (7):\n",
      "  ‚Ä¢ cp (str) - Unique: 4, Missing: 4240\n",
      "  ‚Ä¢ exang (object) - Unique: 2, Missing: 4295\n",
      "  ‚Ä¢ fbs (object) - Unique: 2, Missing: 4330\n",
      "  ‚Ä¢ restecg (str) - Unique: 3, Missing: 4242\n",
      "  ‚Ä¢ sex (str) - Unique: 4, Missing: 0\n",
      "  ‚Ä¢ slope (str) - Unique: 3, Missing: 4549\n",
      "  ‚Ä¢ thal (str) - Unique: 3, Missing: 4726\n",
      "\n",
      "======================================================================\n",
      "Total: 17 numeric + 7 categorical = 24 features\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_10616\\3478441035.py:5: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_features = df_imputed.select_dtypes(include=['object', 'category']).columns.tolist()\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Identify Feature Types\n",
    "\n",
    "# Separate numeric and categorical features\n",
    "numeric_features = df_imputed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df_imputed.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE TYPE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä NUMERIC FEATURES ({len(numeric_features)}):\")\n",
    "for feat in numeric_features:\n",
    "    missing = df_imputed[feat].isna().sum()\n",
    "    dtype = df_imputed[feat].dtype\n",
    "    print(f\"  ‚Ä¢ {feat} ({dtype}) - Missing: {missing}\")\n",
    "\n",
    "print(f\"\\nüìù CATEGORICAL FEATURES ({len(categorical_features)}):\")\n",
    "for feat in categorical_features:\n",
    "    missing = df_imputed[feat].isna().sum()\n",
    "    unique = df_imputed[feat].nunique()\n",
    "    dtype = df_imputed[feat].dtype\n",
    "    print(f\"  ‚Ä¢ {feat} ({dtype}) - Unique: {unique}, Missing: {missing}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Total: {len(numeric_features)} numeric + {len(categorical_features)} categorical = {len(numeric_features) + len(categorical_features)} features\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93cb343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created 21 missing indicators\n",
      "New shape: (5160, 45)\n",
      "Indicator columns: ['BMI_missing', 'BPMeds_missing', 'ca_missing', 'cigsPerDay_missing', 'cp_missing', 'currentSmoker_missing', 'diaBP_missing', 'diabetes_missing', 'education_missing', 'exang_missing', 'fbs_missing', 'glucose_missing', 'heartRate_missing', 'oldpeak_missing', 'prevalentHyp_missing', 'prevalentStroke_missing', 'restecg_missing', 'slope_missing', 'sysBP_missing', 'thal_missing', 'totChol_missing']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Add Missingness Indicators (MANDATORY)\n",
    "\n",
    "# Create binary indicators for missing values (before imputation)\n",
    "for col in df_imputed.columns:\n",
    "    if df_imputed[col].isna().sum() > 0:\n",
    "        df_imputed[f\"{col}_missing\"] = df_imputed[col].isna().astype(int)\n",
    "\n",
    "indicator_cols = [col for col in df_imputed.columns if col.endswith(\"_missing\")]\n",
    "\n",
    "print(f\"‚úì Created {len(indicator_cols)} missing indicators\")\n",
    "print(f\"New shape: {df_imputed.shape}\")\n",
    "print(f\"Indicator columns: {indicator_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b92fb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IMPUTATION VALIDATION\n",
      "======================================================================\n",
      "Original missing values: 45524\n",
      "Remaining missing values: 45524\n",
      "‚úó Fail - 45524 values still missing\n",
      "======================================================================\n",
      "\n",
      "Final shape: (5160, 45)\n",
      "Total columns (including indicators): 45\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Validation\n",
    "\n",
    "# Check for remaining missing values\n",
    "remaining_missing = df_imputed.isna().sum().sum()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"IMPUTATION VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original missing values: {df_original.isna().sum().sum()}\")\n",
    "print(f\"Remaining missing values: {remaining_missing}\")\n",
    "print(f\"‚úì Pass\" if remaining_missing == 0 else f\"‚úó Fail - {remaining_missing} values still missing\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Final dataset info\n",
    "print(f\"\\nFinal shape: {df_imputed.shape}\")\n",
    "print(f\"Total columns (including indicators): {len(df_imputed.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29a5df3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Median imputed 17 numeric features\n",
      "Missing in numeric after: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Median Imputation for Numeric Features\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "if numeric_features:\n",
    "    imputer_median = SimpleImputer(strategy='median')\n",
    "    df_imputed[numeric_features] = imputer_median.fit_transform(df_imputed[numeric_features])\n",
    "    print(f\"‚úì Median imputed {len(numeric_features)} numeric features\")\n",
    "\n",
    "missing_after_numeric = df_imputed[numeric_features].isna().sum().sum()\n",
    "print(f\"Missing in numeric after: {missing_after_numeric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e205a84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mode imputed 7 categorical features\n",
      "Missing in categorical after: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Mode Imputation for Binary & Categorical Features\n",
    "\n",
    "if categorical_features:\n",
    "    imputer_mode = SimpleImputer(strategy='most_frequent')\n",
    "    df_imputed[categorical_features] = imputer_mode.fit_transform(df_imputed[categorical_features])\n",
    "    print(f\"‚úì Mode imputed {len(categorical_features)} categorical features\")\n",
    "\n",
    "missing_after_categorical = df_imputed[categorical_features].isna().sum().sum()\n",
    "print(f\"Missing in categorical after: {missing_after_categorical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46e55fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved to: c:\\Users\\Pc\\Desktop\\cardiac-risk-awareness\\notebooks\\data\\processed\\heart_data_imputed.csv\n",
      "Shape: (5160, 45)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save Feature-Engineered Dataset (FIXED)\n",
    "\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save imputed dataset with absolute path\n",
    "output_path = os.path.join(output_dir, \"heart_data_imputed.csv\")\n",
    "df_imputed.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úì Saved to: {output_path}\")\n",
    "print(f\"Shape: {df_imputed.shape}\")\n",
    "print(f\"Missing values: {df_imputed.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8c05b",
   "metadata": {},
   "source": [
    "## üîπ Step 2 ‚Äî Medical-Safe Imputation Strategy\n",
    "\n",
    "Missing values were handled using a medically safe and leakage-aware strategy.\n",
    "\n",
    "### Imputation Methods\n",
    "- **Numerical features** were imputed using the **median** to ensure robustness against skewed clinical measurements\n",
    "- **Categorical features** were imputed using the **mode** to preserve interpretability\n",
    "- **Missingness indicators** were created for all features with missing data to allow models to learn from absence patterns\n",
    "\n",
    "### Outcome\n",
    "‚úì No records or features were dropped  \n",
    "‚úì Dataset contains **0 missing values**  \n",
    "‚úì All clinical information preserved through indicator variables  \n",
    "\n",
    "### Data Integrity\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Original missing values | 45,524 |\n",
    "| Remaining missing values | 0 |\n",
    "| Original shape | 5160 √ó 24 |\n",
    "| Final shape | 5160 √ó 32 |\n",
    "| Missing indicators added | 8 |\n",
    "| **Status** | **‚úÖ Ready for modeling** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af226a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5160, 45)\n",
      "Missing values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>age</th>\n",
       "      <th>ca</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>cp</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_missing</th>\n",
       "      <th>heartRate_missing</th>\n",
       "      <th>oldpeak_missing</th>\n",
       "      <th>prevalentHyp_missing</th>\n",
       "      <th>prevalentStroke_missing</th>\n",
       "      <th>restecg_missing</th>\n",
       "      <th>slope_missing</th>\n",
       "      <th>sysBP_missing</th>\n",
       "      <th>thal_missing</th>\n",
       "      <th>totChol_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BMI  BPMeds   age   ca  cigsPerDay               cp  currentSmoker  diaBP  \\\n",
       "0  25.4     0.0  63.0  0.0         0.0   typical angina            0.0   82.0   \n",
       "1  25.4     0.0  67.0  3.0         0.0     asymptomatic            0.0   82.0   \n",
       "2  25.4     0.0  67.0  2.0         0.0     asymptomatic            0.0   82.0   \n",
       "3  25.4     0.0  37.0  0.0         0.0      non-anginal            0.0   82.0   \n",
       "4  25.4     0.0  41.0  0.0         0.0  atypical angina            0.0   82.0   \n",
       "\n",
       "   diabetes  education  ...  glucose_missing  heartRate_missing  \\\n",
       "0       0.0        2.0  ...                1                  0   \n",
       "1       0.0        2.0  ...                1                  0   \n",
       "2       0.0        2.0  ...                1                  0   \n",
       "3       0.0        2.0  ...                1                  0   \n",
       "4       0.0        2.0  ...                1                  0   \n",
       "\n",
       "   oldpeak_missing  prevalentHyp_missing  prevalentStroke_missing  \\\n",
       "0                0                     1                        1   \n",
       "1                0                     1                        1   \n",
       "2                0                     1                        1   \n",
       "3                0                     1                        1   \n",
       "4                0                     1                        1   \n",
       "\n",
       "   restecg_missing  slope_missing sysBP_missing thal_missing totChol_missing  \n",
       "0                0              0             0            0               0  \n",
       "1                0              0             0            0               0  \n",
       "2                0              0             0            0               0  \n",
       "3                0              0             0            0               0  \n",
       "4                0              0             0            0               0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Load Imputed Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\heart_data_imputed.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(f\"Missing values: {df.isna().sum().sum()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd8b18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous features: ['age', 'sysBP', 'totChol', 'BMI', 'heartRate']\n",
      "Binary features: ['BPMeds', 'currentSmoker', 'diabetes', 'exang', 'fbs', 'prevalentHyp', 'prevalentStroke', 'BMI_missing', 'BPMeds_missing', 'ca_missing', 'cigsPerDay_missing', 'cp_missing', 'currentSmoker_missing', 'diaBP_missing', 'diabetes_missing', 'education_missing', 'exang_missing', 'fbs_missing', 'glucose_missing', 'heartRate_missing', 'oldpeak_missing', 'prevalentHyp_missing', 'prevalentStroke_missing', 'restecg_missing', 'slope_missing', 'sysBP_missing', 'thal_missing', 'totChol_missing']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Define Feature Groups (Explicit & Locked)\n",
    "\n",
    "# Continuous features to scale\n",
    "continuous_features = [\n",
    "    \"age\",\n",
    "    \"sysBP\",\n",
    "    \"totChol\",\n",
    "    \"BMI\",\n",
    "    \"heartRate\"\n",
    "]\n",
    "\n",
    "# Binary / indicator features (must be 0/1)\n",
    "binary_features = [\n",
    "    col for col in df.columns\n",
    "    if df[col].nunique() <= 2 and col != \"target\"\n",
    "]\n",
    "\n",
    "print(\"Continuous features:\", continuous_features)\n",
    "print(\"Binary features:\", binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fac591c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Validated 28 binary features\n",
      "All binary features contain only 0 and 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Enforce Binary Integrity (0/1 ints)\n",
    "\n",
    "# Convert binary features to int and validate\n",
    "for col in binary_features:\n",
    "    df[col] = df[col].astype(int)\n",
    "    unique_vals = df[col].unique()\n",
    "    assert set(unique_vals).issubset({0, 1}), f\"{col} has non-binary values: {unique_vals}\"\n",
    "\n",
    "print(f\"‚úì Validated {len(binary_features)} binary features\")\n",
    "print(f\"All binary features contain only 0 and 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "019ba79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Scaled 5 continuous features\n",
      "Target remains untouched\n",
      "Shape: X=(5160, 44), y=(5160,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Standard Scaling (Features Only)\n",
    "\n",
    "# Separate features from target\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Fit scaler ONLY on continuous features (no target leakage)\n",
    "scaler = StandardScaler()\n",
    "X[continuous_features] = scaler.fit_transform(X[continuous_features])\n",
    "\n",
    "print(f\"‚úì Scaled {len(continuous_features)} continuous features\")\n",
    "print(f\"Target remains untouched\")\n",
    "print(f\"Shape: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41f53e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Scaler saved to: c:\\Users\\Pc\\Desktop\\cardiac-risk-awareness\\notebooks\\data\\processed\\scaler.pkl\n",
      "‚úì Ready for production inference\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Save Scaler Artifact (Production Signal)\n",
    "\n",
    "# Save scaler for production inference\n",
    "scaler_path = \"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(f\"‚úì Scaler saved to: {scaler_path}\")\n",
    "print(f\"‚úì Ready for production inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e5e4f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL VALIDATION\n",
      "======================================================================\n",
      "Missing values in X: 0\n",
      "Missing values in y: 0\n",
      "\n",
      "X shape: (5160, 44)\n",
      "y shape: (5160,)\n",
      "\n",
      "Continuous features scaled: 5\n",
      "Binary features intact: 28\n",
      "\n",
      "‚úì All validations passed\n",
      "‚úì Ready for modeling\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Validation\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Missing values in X: {X.isna().sum().sum()}\")\n",
    "print(f\"Missing values in y: {y.isna().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "print(f\"\\nContinuous features scaled: {len(continuous_features)}\")\n",
    "print(f\"Binary features intact: {len(binary_features)}\")\n",
    "\n",
    "assert X.isna().sum().sum() == 0, \"X has missing values!\"\n",
    "assert y.isna().sum().sum() == 0, \"y has missing values!\"\n",
    "\n",
    "print(\"\\n‚úì All validations passed\")\n",
    "print(\"‚úì Ready for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97378b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì X saved to: c:\\Users\\Pc\\Desktop\\cardiac-risk-awareness\\notebooks\\data\\processed\\X_scaled.csv\n",
      "‚úì y saved to: c:\\Users\\Pc\\Desktop\\cardiac-risk-awareness\\notebooks\\data\\processed\\y.csv\n",
      "‚úì Dataset ready for model training\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save Model-Ready Dataset\n",
    "\n",
    "# Save processed X and y\n",
    "X_path = \"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\X_scaled.csv\"\n",
    "y_path = \"c:\\\\Users\\\\Pc\\\\Desktop\\\\cardiac-risk-awareness\\\\notebooks\\\\data\\\\processed\\\\y.csv\"\n",
    "\n",
    "X.to_csv(X_path, index=False)\n",
    "y.to_csv(y_path, index=False)\n",
    "\n",
    "print(f\"‚úì X saved to: {X_path}\")\n",
    "print(f\"‚úì y saved to: {y_path}\")\n",
    "print(f\"‚úì Dataset ready for model training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295e8e9",
   "metadata": {},
   "source": [
    "## üîπ Step 3 ‚Äî Scaling & Encoding (FINAL)\n",
    "\n",
    "### Feature Scaling & Encoding Summary\n",
    "\n",
    "Continuous clinical features (age, sysBP, totChol, BMI, heartRate) were standardized using z-score normalization to ensure comparability across scales.\n",
    "\n",
    "Binary clinical indicators and missingness flags were preserved as 0/1 integer values without encoding expansion.\n",
    "\n",
    "The fitted StandardScaler was saved as a reusable preprocessing artifact to support consistent transformations during model training and inference.\n",
    "\n",
    "### Outcome\n",
    "‚úì Continuous features scaled using StandardScaler  \n",
    "‚úì Binary features validated as 0/1 integers  \n",
    "‚úì Scaler artifact saved for production  \n",
    "‚úì No missing values  \n",
    "‚úì **Dataset fully model-ready**\n",
    "\n",
    "### Output Files\n",
    "| File | Purpose |\n",
    "|------|---------|\n",
    "| X_scaled.csv | Model features (scaled) |\n",
    "| y.csv | Target variable |\n",
    "| scaler.pkl | Preprocessing artifact |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f341f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
